{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import np_utils, generic_utils\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>S012C001P007R001A001_rgb.avi_frame0.jpg</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>S012C001P007R001A001_rgb.avi_frame1.jpg</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>S012C001P007R001A001_rgb.avi_frame10.jpg</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>S012C001P007R001A001_rgb.avi_frame11.jpg</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>S012C001P007R001A001_rgb.avi_frame12.jpg</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      image   class\n",
       "0   S012C001P007R001A001_rgb.avi_frame0.jpg  Others\n",
       "1   S012C001P007R001A001_rgb.avi_frame1.jpg  Others\n",
       "2  S012C001P007R001A001_rgb.avi_frame10.jpg  Others\n",
       "3  S012C001P007R001A001_rgb.avi_frame11.jpg  Others\n",
       "4  S012C001P007R001A001_rgb.avi_frame12.jpg  Others"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(r'D:\\2020Spring\\636_project\\data\\train_new.csv')\n",
    "train.head()\n",
    "#print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 15, 112, 112, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating an empty list\n",
    "#train_image = []\n",
    "#train_image_temp = []\n",
    "X = []\n",
    "i_count = train.shape[0]\n",
    "i_count = int(i_count/15)\n",
    "print(i_count)\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(i_count)):\n",
    "#for i in range(150):\n",
    "    train_image = []\n",
    "    train_image_temp = []\n",
    "    for j in range(15):\n",
    "        # loading the image and keeping the target size as (224,224,3)\n",
    "        img = image.load_img(r'D:\\2020Spring\\636_project\\data\\train_1/'+train['image'][i*15+j])\n",
    "        #print(i*15+j)\n",
    "        #print(train['image'][i*15+j])\n",
    "        # converting it to array\n",
    "        img = image.img_to_array(img)\n",
    "        # appending the image to the train_image list\n",
    "        train_image_temp.append(img)\n",
    "        #print(len(train_image_temp))\n",
    "    #train_image.append(train_image_temp)\n",
    "    X.append(np.array(train_image_temp,'float16'))\n",
    "#print(train_image[2])\n",
    "#train_image.dtype = 'float16'\n",
    "# converting the list to numpy array\n",
    "#X = np.array(train_image)\n",
    "X_train = np.array(X,dtype='float16')\n",
    "# shape of the array\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "label = np.zeros(len(X_train),dtype = int)\n",
    "count = 5\n",
    "for i in tqdm(range(len(X_train))):\n",
    "    if (i == count and i < 48):\n",
    "        label[i] = 1\n",
    "        count += 6\n",
    "    if  (i == 48 or i == 54):\n",
    "        label[i] = 1\n",
    "    if (i > 59):\n",
    "        label[i] = 1\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlabel = np.zeros(len(X_train),dtype = int)\\ncount = 40\\nfor i in tqdm(range(len(X_train))):\\n    if (i == count):\\n        label[i] = 1\\n        count += 60\\n#print(label[101])\\n\\nnum_1 = train['image']\\nprint(num_1)\\nlabel = np.zeros(len(X_train),dtype = int)\\nfor i in tqdm(range(len(X_train))):\\n    num = num_1[i].split('\\\\',5)[5]\\n    # creating the image name\\n    #print(images[i].split('_rgb')[0].split('A')[1])\\n    if (num[i].split('_rgb')[0].split('A')[1] == '041'):\\n        label.append('Cough')\\n    # creating the class of image\\n    else:\\n        label.append('Others')\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "label = np.zeros(len(X_train),dtype = int)\n",
    "count = 40\n",
    "for i in tqdm(range(len(X_train))):\n",
    "    if (i == count):\n",
    "        label[i] = 1\n",
    "        count += 60\n",
    "#print(label[101])\n",
    "\n",
    "num_1 = train['image']\n",
    "print(num_1)\n",
    "label = np.zeros(len(X_train),dtype = int)\n",
    "for i in tqdm(range(len(X_train))):\n",
    "    num = num_1[i].split('\\\\',5)[5]\n",
    "    # creating the image name\n",
    "    #print(images[i].split('_rgb')[0].split('A')[1])\n",
    "    if (num[i].split('_rgb')[0].split('A')[1] == '041'):\n",
    "        label.append('Cough')\n",
    "    # creating the class of image\n",
    "    else:\n",
    "        label.append('Others')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the training and validation set\n",
    "X_train = X_train.astype('float32')\n",
    "X_train -= np.mean(X_train)\n",
    "X_train /=np.max(X_train)\n",
    "\n",
    "label = np_utils.to_categorical(label, 2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, label, random_state=42, test_size=0.2, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(32, (5, 5, 5), padding=\"same\", name=\"conv1\", input_shape=(15, 112, ..., activation=\"relu\")`\n",
      "  \n",
      "D:\\Software\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "D:\\Software\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, kernel_initializer=\"normal\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution3D(32, 5, 5, 5, padding='same', name='conv1', dim_ordering='tf', input_shape=(15,112,112,3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(3, 3, 3)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, init='normal', activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2,init='normal'))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/15\n",
      "80/80 [==============================] - ETA: 43s - loss: 1.2344 - accuracy: 0.625 - ETA: 32s - loss: 5.5855 - accuracy: 0.593 - ETA: 21s - loss: 46.9553 - accuracy: 0.52 - ETA: 10s - loss: 42.0002 - accuracy: 0.53 - 55s 683ms/step - loss: 38.1238 - accuracy: 0.5500 - val_loss: 1.6010 - val_accuracy: 0.7500\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - ETA: 42s - loss: 4.6704 - accuracy: 0.625 - ETA: 31s - loss: 3.0842 - accuracy: 0.687 - ETA: 21s - loss: 5.1527 - accuracy: 0.604 - ETA: 10s - loss: 5.0034 - accuracy: 0.609 - 54s 676ms/step - loss: 4.4904 - accuracy: 0.6000 - val_loss: 0.9266 - val_accuracy: 0.7500\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - ETA: 43s - loss: 1.4419 - accuracy: 0.687 - ETA: 32s - loss: 1.3586 - accuracy: 0.750 - ETA: 21s - loss: 1.4590 - accuracy: 0.750 - ETA: 10s - loss: 2.2556 - accuracy: 0.734 - 55s 682ms/step - loss: 1.9730 - accuracy: 0.7250 - val_loss: 0.4352 - val_accuracy: 0.7500\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - ETA: 42s - loss: 0.5559 - accuracy: 0.812 - ETA: 31s - loss: 0.6810 - accuracy: 0.781 - ETA: 21s - loss: 0.6503 - accuracy: 0.708 - ETA: 10s - loss: 0.6930 - accuracy: 0.687 - 54s 678ms/step - loss: 0.6678 - accuracy: 0.7000 - val_loss: 0.4532 - val_accuracy: 0.8000\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - ETA: 42s - loss: 0.5403 - accuracy: 0.625 - ETA: 31s - loss: 0.7427 - accuracy: 0.593 - ETA: 21s - loss: 0.6106 - accuracy: 0.687 - ETA: 10s - loss: 0.6147 - accuracy: 0.687 - 54s 681ms/step - loss: 0.5674 - accuracy: 0.7250 - val_loss: 0.4619 - val_accuracy: 0.7500\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - ETA: 42s - loss: 0.5382 - accuracy: 0.687 - ETA: 31s - loss: 0.4936 - accuracy: 0.718 - ETA: 21s - loss: 0.6216 - accuracy: 0.604 - ETA: 10s - loss: 0.5472 - accuracy: 0.687 - 55s 684ms/step - loss: 0.4894 - accuracy: 0.7250 - val_loss: 0.4750 - val_accuracy: 0.7500\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - ETA: 43s - loss: 0.8107 - accuracy: 0.562 - ETA: 32s - loss: 0.6372 - accuracy: 0.625 - ETA: 21s - loss: 0.6011 - accuracy: 0.666 - ETA: 10s - loss: 0.5539 - accuracy: 0.687 - 55s 686ms/step - loss: 0.4910 - accuracy: 0.7500 - val_loss: 0.5448 - val_accuracy: 0.7500\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - ETA: 42s - loss: 0.6761 - accuracy: 0.812 - ETA: 32s - loss: 0.5038 - accuracy: 0.843 - ETA: 21s - loss: 0.4722 - accuracy: 0.833 - ETA: 10s - loss: 0.5072 - accuracy: 0.796 - 55s 686ms/step - loss: 0.6168 - accuracy: 0.7625 - val_loss: 1.0104 - val_accuracy: 0.5000\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - ETA: 42s - loss: 0.7599 - accuracy: 0.750 - ETA: 32s - loss: 0.5181 - accuracy: 0.812 - ETA: 21s - loss: 0.4867 - accuracy: 0.812 - ETA: 10s - loss: 0.9532 - accuracy: 0.765 - 55s 685ms/step - loss: 0.8493 - accuracy: 0.7750 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - ETA: 42s - loss: 0.5222 - accuracy: 0.750 - ETA: 32s - loss: 0.4830 - accuracy: 0.781 - ETA: 21s - loss: 0.4863 - accuracy: 0.770 - ETA: 10s - loss: 0.4451 - accuracy: 0.796 - 57s 713ms/step - loss: 0.4483 - accuracy: 0.7875 - val_loss: 0.4588 - val_accuracy: 0.7500\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - ETA: 45s - loss: 0.5758 - accuracy: 0.687 - ETA: 34s - loss: 0.4755 - accuracy: 0.781 - ETA: 22s - loss: 0.4678 - accuracy: 0.791 - ETA: 11s - loss: 0.4566 - accuracy: 0.781 - 58s 729ms/step - loss: 0.4398 - accuracy: 0.7875 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - ETA: 44s - loss: 0.3637 - accuracy: 0.750 - ETA: 33s - loss: 0.3771 - accuracy: 0.781 - ETA: 22s - loss: 0.3951 - accuracy: 0.812 - ETA: 11s - loss: 0.4194 - accuracy: 0.781 - 58s 725ms/step - loss: 0.4591 - accuracy: 0.7500 - val_loss: 0.7038 - val_accuracy: 0.7500\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - ETA: 44s - loss: 0.2538 - accuracy: 0.937 - ETA: 33s - loss: 0.7334 - accuracy: 0.875 - ETA: 22s - loss: 1.8939 - accuracy: 0.770 - ETA: 11s - loss: 1.9948 - accuracy: 0.734 - 58s 729ms/step - loss: 6.8771 - accuracy: 0.6750 - val_loss: 1.3072 - val_accuracy: 0.5000\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - ETA: 44s - loss: 0.8640 - accuracy: 0.750 - ETA: 33s - loss: 0.7661 - accuracy: 0.625 - ETA: 22s - loss: 0.6575 - accuracy: 0.708 - ETA: 11s - loss: 0.6242 - accuracy: 0.703 - 58s 729ms/step - loss: 0.5894 - accuracy: 0.7250 - val_loss: 0.4789 - val_accuracy: 0.7500\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - ETA: 44s - loss: 0.3114 - accuracy: 0.812 - ETA: 33s - loss: 0.3670 - accuracy: 0.843 - ETA: 22s - loss: 0.3730 - accuracy: 0.875 - ETA: 11s - loss: 0.5030 - accuracy: 0.812 - 58s 723ms/step - loss: 0.5064 - accuracy: 0.7625 - val_loss: 0.5564 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, validation_data=(X_test,y_test),\n",
    "          batch_size = 16, epochs = 15, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 75ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=32)\n",
    "#print('Test score:', score[0])\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5563778281211853, 0.5]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_loss=hist.history['loss']\\nval_loss=hist.history['val_loss']\\ntrain_acc=hist.history['accrucy']\\nval_acc=hist.history['val_acc']\\nxc=range(100)\\n\\nplt.figure(1,figsize=(7,5))\\nplt.plot(xc,train_loss)\\nplt.plot(xc,val_loss)\\nplt.xlabel('num of Epochs')\\nplt.ylabel('loss')\\nplt.title('train_loss vs val_loss')\\nplt.grid(True)\\nplt.legend(['train','val'])\\nplt.style.available # use bmh, classic,ggplot for big pictures\\nplt.style.use(['classic'])\\n\\nplt.figure(2,figsize=(7,5))\\nplt.plot(xc,train_acc)\\nplt.plot(xc,val_acc)\\nplt.xlabel('num of Epochs')\\nplt.ylabel('accuracy')\\nplt.title('train_acc vs val_acc')\\nplt.grid(True)\\nplt.legend(['train','val'],loc=4)\\n#print plt.style.available # use bmh, classic,ggplot for big pictures\\nplt.style.use(['classic'])\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['accrucy']\n",
    "val_acc=hist.history['val_acc']\n",
    "xc=range(100)\n",
    "\n",
    "plt.figure(1,figsize=(7,5))\n",
    "plt.plot(xc,train_loss)\n",
    "plt.plot(xc,val_loss)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'])\n",
    "plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "plt.figure(2,figsize=(7,5))\n",
    "plt.plot(xc,train_acc)\n",
    "plt.plot(xc,val_acc)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'],loc=4)\n",
    "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the .txt file which have names of test videos\n",
    "f = open(r\"D:\\2020Spring\\636_project\\data\\test_list.txt\", \"r\")\n",
    "temp = f.read()\n",
    "videos = temp.split('\\n')\n",
    "\n",
    "# creating a dataframe having video names\n",
    "test = pd.DataFrame()\n",
    "test['video_name'] = videos\n",
    "test = test[:]\n",
    "#print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 960/960 [09:30<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 15, 112, 112, 3)\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# storing the frames from test videos\n",
    "Test_array = []\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "#for i in range(1):\n",
    "    test_image_temp = []\n",
    "    count = 0\n",
    "    videoFile = test['video_name'][i]\n",
    "    cap = cv2.VideoCapture(r'D:\\2020Spring\\636_project\\data\\test_data1/' + videoFile)   # capturing the video from the given path\n",
    "    frameCount = cap.get(7) #frame counts\n",
    "    x = math.floor(frameCount / 15)\n",
    "    #print([frameCount,x])\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1) #current frame number\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if (count == 15):\n",
    "            break\n",
    "        if (frameId == (x * count)):\n",
    "            # storing the frames in a new folder named train_1\n",
    "            frame=cv2.resize(frame,(112,112),interpolation=cv2.INTER_AREA)\n",
    "            #filename =r'D:\\2020Spring\\636_project\\data\\test_1/' + videoFile +\"_frame%d.jpg\" % count;count+=1\n",
    "            #cv2.imwrite(filename, frame)\n",
    "            frame = image.img_to_array(frame)\n",
    "            # appending the image to the train_image list\n",
    "            test_image_temp.append(frame)\n",
    "            #print(len(test_image_temp))\n",
    "            count+=1\n",
    "    cap.release()\n",
    "    Test_array.append(np.array(test_image_temp,dtype='float16'))\n",
    "Test_array_f = np.array(Test_array,dtype='float16')\n",
    "Test_array_f = Test_array_f.astype('float32')\n",
    "Test_array_f -= np.mean(Test_array_f)\n",
    "Test_array_f /=np.max(Test_array_f)\n",
    "#Test_array_f[0][:][:][:][:] = Test_array[:][:][:][:]\n",
    "print(Test_array_f.shape)\n",
    "#make prediction\n",
    "prediction = model.predict_classes(Test_array_f)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
